{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# remerge uplift report\n",
    "\n",
    "This notebook allows you to validate remerge provided uplift reporting numbers. To do so it downloads and analyses exported campaign and event data from S3 (access credentials to the S3 bucket are provided by your remerge account manager). The campaign data contains all users that remerge marked to be part of an uplift test, the A/B group assignment, the timestamp of marking, conversion events (click, app open or similar) and their cost. The event data reflects the event stream provided by the customer and includes events, their timestamp and revenue (if any). \n",
    "\n",
    "To verify that the group split is random and has no bias, user events / attributes before campaign start can be compared and check for an equal distribution in test and control group. For example the user age distribution, the user activity distribution or the average spend per user  should be the same in both groups pre campaign. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import needed packages\n",
    "\n",
    "This notebook/script needs pandas and scipy for analysis and boto to access data store on S3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import boto3 # check if we need to import this\n",
    "import re\n",
    "import os\n",
    "import gzip\n",
    "import scipy\n",
    "import scipy.stats \n",
    "import s3fs\n",
    "from IPython.display import display # so we can run this as script as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set the customer name, audience + access credentials for the S3 bucket and path. Furthermore the event for which we want to evaluate the uplift needs to be set `revenue_event`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer = \"\"\n",
    "audience = \"\"\n",
    "revenue_event = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"AWS_ACCESS_KEY_ID\"] = \"xxxxxxxx\"\n",
    "# os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"xxxxxxxx\"\n",
    "\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = \"\"\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.date_range(start='2019-02-14',end='2019-02-27')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"s3://remerge-customers/{0}/uplift_data/{1}/\".format(customer,audience)\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper to download CSV files, convert to DF and print time needed\n",
    "def read_csv(date,source):\n",
    "    now = datetime.now()\n",
    "    filename = path + source+'/'+date.strftime('%Y%m%d')+'.csv.gz'\n",
    "    cache_dir = 'cache/'+source\n",
    "    cache_filename = cache_dir + '/' + date.strftime('%Y%m%d')+'.parquet'\n",
    "    if os.path.exists(cache_filename):\n",
    "        print(now, \"loading from cache\", cache_filename)\n",
    "        return pd.read_parquet(cache_filename, engine='pyarrow')\n",
    "    print(now, \"start loading CSV for\", date)\n",
    "    df = pd.read_csv(filename, escapechar='\\\\')\n",
    "    print(datetime.now(), \"finished loading CSV for\", date.strftime('%d.%m.%Y'), \"took\", datetime.now()-now)\n",
    "    if not os.path.exists(cache_dir):\n",
    "        os.makedirs(cache_dir)\n",
    "    df.to_parquet(cache_filename, engine='pyarrow')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CSV data from S3\n",
    "\n",
    "Load mark,spend and event data from S3. \n",
    "## IMPORTANT\n",
    "**The event data is usually quite large (several GB) so this operation might take several minutes or hours to complete, depending on the size and connection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-07 16:21:27.568440 loading from cache cache/marks_and_spend/20190214.parquet\n",
      "2019-03-07 16:21:27.738527 loading from cache cache/marks_and_spend/20190215.parquet\n",
      "2019-03-07 16:21:27.776029 loading from cache cache/marks_and_spend/20190216.parquet\n",
      "2019-03-07 16:21:27.807911 loading from cache cache/marks_and_spend/20190217.parquet\n",
      "2019-03-07 16:21:27.832332 loading from cache cache/marks_and_spend/20190218.parquet\n",
      "2019-03-07 16:21:27.854468 loading from cache cache/marks_and_spend/20190219.parquet\n",
      "2019-03-07 16:21:27.957119 loading from cache cache/marks_and_spend/20190220.parquet\n",
      "2019-03-07 16:21:28.013446 loading from cache cache/marks_and_spend/20190221.parquet\n",
      "2019-03-07 16:21:28.062236 loading from cache cache/marks_and_spend/20190222.parquet\n",
      "2019-03-07 16:21:28.108072 loading from cache cache/marks_and_spend/20190223.parquet\n",
      "2019-03-07 16:21:28.146834 loading from cache cache/marks_and_spend/20190224.parquet\n",
      "2019-03-07 16:21:28.197832 loading from cache cache/marks_and_spend/20190225.parquet\n",
      "2019-03-07 16:21:28.245036 loading from cache cache/marks_and_spend/20190226.parquet\n",
      "2019-03-07 16:21:28.293574 loading from cache cache/marks_and_spend/20190227.parquet\n"
     ]
    }
   ],
   "source": [
    "bid_df = pd.concat([read_csv(date,'marks_and_spend') for date in dates], ignore_index = True, verify_integrity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-07 16:25:01.729613 start loading CSV for 2019-02-14 00:00:00\n",
      "2019-03-07 16:33:54.249781 finished loading CSV for 14.02.2019 took 0:08:52.520218\n",
      "2019-03-07 16:34:09.308277 start loading CSV for 2019-02-15 00:00:00\n",
      "2019-03-07 16:42:26.072868 finished loading CSV for 15.02.2019 took 0:08:16.764644\n",
      "2019-03-07 16:42:42.233706 start loading CSV for 2019-02-16 00:00:00\n",
      "2019-03-07 16:54:20.098443 finished loading CSV for 16.02.2019 took 0:11:37.864803\n",
      "2019-03-07 16:54:36.198460 start loading CSV for 2019-02-17 00:00:00\n",
      "2019-03-07 17:11:24.099303 finished loading CSV for 17.02.2019 took 0:16:47.900896\n",
      "2019-03-07 17:11:38.670664 start loading CSV for 2019-02-18 00:00:00\n",
      "2019-03-07 17:22:45.158189 finished loading CSV for 18.02.2019 took 0:11:06.487590\n",
      "2019-03-07 17:23:02.600611 start loading CSV for 2019-02-19 00:00:00\n",
      "2019-03-07 17:30:06.088882 finished loading CSV for 19.02.2019 took 0:07:03.488369\n",
      "2019-03-07 17:30:22.702401 start loading CSV for 2019-02-20 00:00:00\n",
      "2019-03-07 17:36:42.872055 finished loading CSV for 20.02.2019 took 0:06:20.169700\n",
      "2019-03-07 17:36:59.176595 start loading CSV for 2019-02-21 00:00:00\n",
      "2019-03-07 17:45:49.588172 finished loading CSV for 21.02.2019 took 0:08:50.411649\n",
      "2019-03-07 17:46:04.323201 start loading CSV for 2019-02-22 00:00:00\n",
      "2019-03-07 18:00:57.030008 finished loading CSV for 22.02.2019 took 0:14:52.706847\n",
      "2019-03-07 18:01:11.285584 start loading CSV for 2019-02-23 00:00:00\n",
      "2019-03-07 18:12:18.472652 finished loading CSV for 23.02.2019 took 0:11:07.187124\n",
      "2019-03-07 18:12:32.808943 start loading CSV for 2019-02-24 00:00:00\n",
      "2019-03-07 18:22:26.046007 finished loading CSV for 24.02.2019 took 0:09:53.237136\n",
      "2019-03-07 18:22:42.160466 start loading CSV for 2019-02-25 00:00:00\n",
      "2019-03-07 18:37:53.494224 finished loading CSV for 25.02.2019 took 0:15:11.333805\n",
      "2019-03-07 18:38:09.372573 start loading CSV for 2019-02-26 00:00:00\n",
      "2019-03-07 18:53:18.669139 finished loading CSV for 26.02.2019 took 0:15:09.296621\n",
      "2019-03-07 18:53:33.841521 start loading CSV for 2019-02-27 00:00:00\n"
     ]
    }
   ],
   "source": [
    "attributions_df = pd.concat([read_csv(date,'attributions') for date in dates], ignore_index = True, verify_integrity=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print some statistics of the loaded data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 220850 entries, 0 to 220849\n",
      "Data columns (total 9 columns):\n",
      "ts               220850 non-null object\n",
      "event_type       220850 non-null object\n",
      "ab_test_group    220850 non-null object\n",
      "user_id          220845 non-null object\n",
      "campaign_id      220850 non-null int64\n",
      "cost_currency    5647 non-null object\n",
      "cost             5647 non-null float64\n",
      "cost_eur         5647 non-null float64\n",
      "campaign_name    220850 non-null object\n",
      "dtypes: float64(2), int64(1), object(6)\n",
      "memory usage: 15.2+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>campaign_id</th>\n",
       "      <th>cost</th>\n",
       "      <th>cost_eur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>220850.000000</td>\n",
       "      <td>5647.000000</td>\n",
       "      <td>5647.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>16490.696192</td>\n",
       "      <td>275202.762529</td>\n",
       "      <td>242813.084824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>438.537970</td>\n",
       "      <td>96205.499843</td>\n",
       "      <td>84835.409771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>16171.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>88062.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>16175.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>176328.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>16177.000000</td>\n",
       "      <td>270000.000000</td>\n",
       "      <td>238191.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>17099.000000</td>\n",
       "      <td>330000.000000</td>\n",
       "      <td>291061.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17100.000000</td>\n",
       "      <td>500000.000000</td>\n",
       "      <td>441407.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         campaign_id           cost       cost_eur\n",
       "count  220850.000000    5647.000000    5647.000000\n",
       "mean    16490.696192  275202.762529  242813.084824\n",
       "std       438.537970   96205.499843   84835.409771\n",
       "min     16171.000000  100000.000000   88062.000000\n",
       "25%     16175.000000  200000.000000  176328.000000\n",
       "50%     16177.000000  270000.000000  238191.000000\n",
       "75%     17099.000000  330000.000000  291061.500000\n",
       "max     17100.000000  500000.000000  441407.000000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bid_df.info()\n",
    "bid_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 140545704 entries, 0 to 140545703\n",
      "Data columns (total 11 columns):\n",
      "ts                  object\n",
      "user_id             object\n",
      "event_id            float64\n",
      "partner             object\n",
      "partner_event       object\n",
      "revenue             float64\n",
      "revenue_currency    object\n",
      "revenue_eur         float64\n",
      "ab_test_group       object\n",
      "event_data          object\n",
      "date                object\n",
      "dtypes: float64(3), object(8)\n",
      "memory usage: 11.5+ GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ts                  140545704\n",
       "user_id             140545704\n",
       "event_id                    0\n",
       "partner             140545704\n",
       "partner_event       140545704\n",
       "revenue              10206312\n",
       "revenue_currency    112620385\n",
       "revenue_eur          10206312\n",
       "ab_test_group         6867501\n",
       "event_data          112165510\n",
       "date                140545704\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributions_df.info()\n",
    "attributions_df.describe()\n",
    "attributions_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31045386"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check - remove later\n",
    "attributions_df[\"ts\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uplift report prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', '{:.2f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cost_eur</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ab_test_group</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>control</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>1371165490.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   cost_eur\n",
       "ab_test_group              \n",
       "control                0.00\n",
       "test          1371165490.00"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check - remove later ✅\n",
    "bid_df.groupby(by='ab_test_group')[[\"cost_eur\"]].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ab_test_group\n",
       "control     40827\n",
       "test       161048\n",
       "Name: user_id, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check - remove later ✅\n",
    "bid_df.groupby(by='ab_test_group')['user_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ab_test_group\n",
       "control     39628\n",
       "test       159797\n",
       "Name: user_id, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check - remove later ✅\n",
    "# there should not be duplicate users ids that are in both groups\n",
    "# we need to fix that first\n",
    "bid_df.drop_duplicates('user_id').groupby(by='ab_test_group')['user_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove invalid users\n",
    "\n",
    "Due to a race condition during marking we need to filter out users that are marked as *control* and *test*. In rare cases we see the same user on different servers in the same second, and unknowingly of each other mark him differently. This is going to be fixed in a future version. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2450"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# users with both groups, test is a problem due to racy bids\n",
    "# we need to filter them out and fix this \n",
    "groups_per_user = bid_df.groupby('user_id')['ab_test_group'].nunique()\n",
    "invalid_users = groups_per_user[groups_per_user > 1]\n",
    "invalid_users.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "2019-02-19   714720194413680128.00\n",
       "2019-02-20      277465639950744.00\n",
       "2019-02-21      209884677199881.00\n",
       "Name: revenue_eur, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check - remove for exported notebook\n",
    "attributions_df['date'] = pd.to_datetime(attributions_df['ts']).dt.date\n",
    "attribution_by_date = attributions_df.groupby(by='date')\n",
    "attribution_by_date['revenue_eur'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mark_df dataframe will contain all mark events (without the invalid marks). It is then grouped by the assigend A/B test group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "mark_df = bid_df[bid_df.event_type == 'mark']\n",
    "mark_df = mark_df[~mark_df['user_id'].isin(invalid_users.index)]\n",
    "grouped = mark_df.groupby(by='ab_test_group')\n",
    "control_df = grouped.get_group('control')\n",
    "test_df = grouped.get_group('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ab_test_group\n",
       "control     38377\n",
       "test       156101\n",
       "Name: user_id, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove from final notebook\n",
    "# there shouldn't be any duplicates\n",
    "mark_df.drop_duplicates('user_id').groupby(by='ab_test_group')['user_id'].nunique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the cost of advertising. Remerge tracks monetary valuesin micro currency units. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1371.16549"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ad_spend_micros = bid_df[bid_df.event_type == 'buying_conversion']['cost_eur'].sum()\n",
    "ad_spend = ad_spend_micros / 10**6\n",
    "ad_spend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataframe that contains all relevant revenue events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "revenue_df = attributions_df[pd.notnull(attributions_df['revenue_eur'])]\n",
    "revenue_df = revenue_df[revenue_df.partner_event == revenue_event]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ab_test_group\n",
       "control   211064.63\n",
       "test      840173.60\n",
       "Name: revenue_eur, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check - remove later\n",
    "revenue_df.groupby('ab_test_group')['revenue_eur'].sum() / 10**6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92767"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check - remove later\n",
    "revenue_df['user_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34766241.004789"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanit check - remove later\n",
    "revenue_df['revenue_eur'].sum() / 10**6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remerge marks users per campaign. This analysis looks at the per audience uplift, for that reason we drop duplicate marks for users that were marked by multiple campaigns. If a user was marked once for an audience he will have the same group allocation for consecutive marks unless manually reset on audience level.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_mark_df = mark_df.sort_values('ts')\n",
    "depuplicated_mark_df = sorted_mark_df.drop_duplicates(['user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "194478"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check remove later\n",
    "depuplicated_mark_df['user_id'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ab_test_group\n",
       "control     38377\n",
       "test       156101\n",
       "Name: user_id, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check remove later\n",
    "depuplicated_mark_df.groupby('ab_test_group')['user_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join the marked users with the revenue events and excluded any revenue event that happend before the user was marked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(revenue_df, depuplicated_mark_df, on='user_id')\n",
    "merged_df = merged_df[merged_df.ts_x > merged_df.ts_y]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check - remove later\n",
    "merged_df['date'] = pd.to_datetime(merged_df['ts_x']).dt.date\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate uplift kpis\n",
    "\n",
    "We calculate the incremental revenue and the iROAS in line with the [remerge whitepaper](https://drive.google.com/file/d/1PTJ93Cpjw1BeiVns8dTcs2zDDWmmjpdc/view). Afterwards run a [chi squared test](https://en.wikipedia.org/wiki/Chi-squared_test) on the results to test for significance of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_revenue = merged_df.groupby(by='ab_test_group_y')\n",
    "test_group_size = test_df['user_id'].nunique()\n",
    "test_revenue_micros = grouped_revenue.get_group('test')['revenue_eur'].sum()\n",
    "test_revenue = test_revenue_micros / 10**6\n",
    "control_group_size = control_df['user_id'].nunique()\n",
    "control_revenue_micros = grouped_revenue.get_group('control')['revenue_eur'].sum()\n",
    "control_revenue = control_revenue_micros / 10**6\n",
    "test_conversions = grouped_revenue.get_group('test')['revenue_eur'].count()\n",
    "control_conversion = grouped_revenue.get_group('control')['revenue_eur'].count()\n",
    "ratio = float(test_group_size) / float(control_group_size)\n",
    "scaled_control_conversions = float(control_conversion) * ratio\n",
    "scaled_control_revenue_micros = float(control_revenue_micros) * ratio\n",
    "incremental_conversions = test_conversions - scaled_control_conversions\n",
    "incremental_revenue_micros = test_revenue_micros - scaled_control_revenue_micros\n",
    "incremental_revenue = incremental_revenue_micros / 10**6\n",
    "iroas = incremental_revenue / ad_spend\n",
    "chi_df = pd.DataFrame({\n",
    "    \"conversions\": [control_conversion, test_conversions],\n",
    "    \"total\": [control_group_size, test_group_size]\n",
    "    }, index=['control', 'test'])\n",
    "\n",
    "chi,p,*_ = scipy.stats.chi2_contingency(pd.concat([chi_df.total - chi_df.conversions, chi_df.conversions], axis=1), correction=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ad spend</th>\n",
       "      <td>1371.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total revenue</th>\n",
       "      <td>345024.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test group size</th>\n",
       "      <td>156101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test conversions</th>\n",
       "      <td>1537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test revenue</th>\n",
       "      <td>277092.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>size control group</th>\n",
       "      <td>38377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>control conversion</th>\n",
       "      <td>406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>control revenue</th>\n",
       "      <td>67932.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ratio test/control</th>\n",
       "      <td>4.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>control conversions (scaled)</th>\n",
       "      <td>1651.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>control revenue (scaled)</th>\n",
       "      <td>276318.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incremental conversions</th>\n",
       "      <td>-114.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incremental revenue</th>\n",
       "      <td>773.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rev/conversions test</th>\n",
       "      <td>180.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rev/conversions control</th>\n",
       "      <td>167.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iROAS</th>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chi^2</th>\n",
       "      <td>1.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p-value</th>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>significant</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 value\n",
       "ad spend                       1371.17\n",
       "total revenue                345024.41\n",
       "test group size                 156101\n",
       "test conversions                  1537\n",
       "test revenue                 277092.21\n",
       "size control group               38377\n",
       "control conversion                 406\n",
       "control revenue               67932.20\n",
       "ratio test/control                4.07\n",
       "control conversions (scaled)   1651.43\n",
       "control revenue (scaled)     276318.75\n",
       "incremental conversions        -114.43\n",
       "incremental revenue             773.46\n",
       "rev/conversions test            180.28\n",
       "rev/conversions control         167.32\n",
       "iROAS                             0.56\n",
       "chi^2                             1.67\n",
       "p-value                           0.20\n",
       "significant                       True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show it in nice\n",
    "result_df = pd.DataFrame({\n",
    "    \"ad spend\": ad_spend,\n",
    "    \"total revenue\": test_revenue + control_revenue,\n",
    "    \"test group size\": test_group_size,\n",
    "    \"test conversions\": test_conversions,\n",
    "    \"test revenue\": test_revenue,\n",
    "    \"size control group\": control_group_size,\n",
    "    \"control conversion\": control_conversion,\n",
    "    \"control revenue\": control_revenue,\n",
    "    \"ratio test/control\": ratio,\n",
    "    \"control conversions (scaled)\": scaled_control_conversions,\n",
    "    \"control revenue (scaled)\": scaled_control_revenue_micros / 10**6,\n",
    "    \"incremental conversions\": incremental_conversions,\n",
    "    \"incremental revenue\": incremental_revenue,\n",
    "    \"rev/conversions test\":test_revenue / test_conversions,\n",
    "    \"rev/conversions control\": control_revenue / control_conversion,\n",
    "    \"iROAS\": iroas,\n",
    "    \"chi^2\":chi,\n",
    "    \"p-value\":p,\n",
    "    \"significant\":p>0.05},index=[\"value\"]).transpose()\n",
    "\n",
    "display(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
